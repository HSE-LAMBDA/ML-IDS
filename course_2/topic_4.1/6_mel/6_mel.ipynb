{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8da435-3077-474a-bddf-79a78f310262",
   "metadata": {},
   "source": [
    "# Mel spectrogram\n",
    "\n",
    "We will consider a python library for audio analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a6099-5fc1-4d5b-bb29-d9d6675036c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.testing as np_testing\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee241028-a0e3-4936-bae7-d756a01f3363",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "\n",
    "Import libraries for audio samples preprocessing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac4fa4c-d45a-46c9-89c7-a585f0761792",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74190901-368f-4061-9f52-5711653cfe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4758b71-d149-4580-88d0-b8748aae2ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab6cfa3-6c50-4827-adc2-33085267d2bf",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c864c16-9603-4f85-8c2e-4839271c1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a03959-6a1d-4582-8f4a-a4e5c45a3156",
   "metadata": {},
   "source": [
    "# Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5bfe6-2e75-434d-b4d6-8d1b80fe6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(\"Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015357f5-66b5-495c-b9d0-dc128a6b87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068a5d7-9a70-4d5c-84a8-b94e47131a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555fc226-f1f6-4bf8-9c60-900e1fc121de",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60d064-789e-4cc1-989e-fe7981c6911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listen to the music\n",
    "display(Audio(data=waveform, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8952d5d6-76b6-415f-9e05-f00726201b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(np.arange(waveform.size()[1]) / sample_rate, waveform[0])\n",
    "plt.xlim(0, waveform.size()[1] / sample_rate)\n",
    "plt.xlabel(\"Time (s)\", size=14)\n",
    "plt.title('Sound waveform', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562e34b-85da-4565-abc3-6e7e2ca7fc4c",
   "metadata": {},
   "source": [
    "# Mel spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29bf12-3620-4ed6-a31d-9deaab1a24e2",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af04aed-ff83-475c-b81c-c2a49359d126",
   "metadata": {},
   "source": [
    "Calculate a mel spectrogram for the given audio signal waveform using `torchaudio.transforms.MelSpectrogram()` function. Set the number of Fourier transform frequencies as 1024, window length as 1024, window intersection length as 256, and take 128 mel components.\n",
    "\n",
    "**Hint:** use `sample_rate`, `n_fft`, `win_length`, `hop_length`, and `n_mels` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7f0c2-55eb-4331-b173-346d933d4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram = ...\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "    \n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b0b054-c557-462e-a5d9-d4e10a045f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Spectrogram size: \", spectrogram.size()) # N channels, N mel frequencies, N time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334b8ce-e6f1-40f5-80a5-1ecae99a2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb65f1f-e645-4b73-a109-489e9efff06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "actual  = list(spectrogram.size())\n",
    "desired = [1, 128, 213]\n",
    "np_testing.assert_almost_equal(actual, desired, decimal=1)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6133669-ad7e-41cf-913f-b0d4061fb99d",
   "metadata": {},
   "source": [
    "# Postprocessing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb82435-5c83-4530-8f10-d8215f715bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram postprocessing\n",
    "def apply_compression(spectrogram):\n",
    "    return torch.log(spectrogram.clamp(1e-5))\n",
    "\n",
    "new_spectrogram = apply_compression(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a54cab-cb24-4266-a9b2-67942ace1e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.imshow(new_spectrogram[0, :, :], aspect='auto', cmap='viridis')\n",
    "plt.xlabel('Time frames', size=14)\n",
    "plt.ylabel('Mel frequencies, units', size=14)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3c3ff-3f83-497d-8c9f-1b303b7ea3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
