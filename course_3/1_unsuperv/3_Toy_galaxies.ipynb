{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import hdbscan\n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import MeanShift, AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/HSE-LAMBDA/ML-IDS/raw/main/course_3/1_unsuperv/toy_galaxies_pelican.csv'\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has coordinates of toy galaxies in 3D-space (x,y,z) and true clusters' label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "Axes3D.scatter(ax, data.x,data.y,data.z, marker='.')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that make a plot and print ARI\n",
    "\n",
    "def plot_galaxies(data,cluster):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    Axes3D.scatter(ax,data.x, data.y, data.z, marker='.', c=cluster.labels_);\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    plt.show();\n",
    "\n",
    "    ARI = round(ari(data.label,cluster.labels_),4)\n",
    "\n",
    "\n",
    "    print('ARI = {}'.format(ARI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this task is data clustering. As we have already discussed, before starting to solve the problem, we need to decide what distance metric we will use inside the algorithm and how we will then evaluate the quality of our clustering.\n",
    "\n",
    "Since we have labeled data, to compare the results we will use the previously encountered Adjusted Rand Index (ARI). Now we need to choose a metric for measuring the distances between objects, which any algorithm uses in its work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us try a new method for us - Mean-shift clustering. We will use the one from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html) that uses [RBF](https://en.wikipedia.org/wiki/Radial_basis_function) (Radial Basis Function) kernel. We will make few steps of the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (5,40,10):\n",
    "    cluster = MeanShift(bandwidth=i, n_jobs=-1)\n",
    "    cluster.fit(data[['x','y','z']].to_numpy())\n",
    "    print('i={}, ari={}'.format(i,round(ari(data.label,cluster.labels_),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the grid search the maximum ARI was reached on the bandwidth = 0.8857. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = MeanShift(bandwidth=25, n_jobs=-1)\n",
    "cluster.fit(data[['x','y','z']].to_numpy())\n",
    "\n",
    "plot_galaxies(data,cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different distance metric\n",
    "\n",
    "We can see that our data has a certain structure, namely, the clusters of galaxies are elongated along radii directed to the center. This may lead us to the idea that in order to determine clusters, it is sufficient to know only the direction, but not the remotness. Therefore, we will use the cosine distance as the initial metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try to use it in an advanced clustering algorithm - *HDBSCAN* with the following set of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = hdbscan.HDBSCAN(metric=\"cosine\",\n",
    "                          min_cluster_size=9,\n",
    "                          algorithm=\"generic\",\n",
    "                          alpha=0.8,\n",
    "                          cluster_selection_method='eom')\n",
    "\n",
    "cluster.fit(data[['x','y','z']].to_numpy())\n",
    "\n",
    "round(ari(data.label,cluster.labels_),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, not bad. About $87\\%$ of data we clustered well, but it shows ARI worse than MeanShift. So, does it mean that HDBSCAN works worse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the perfomance of the HDBSCAN with 'cosine' and 'euclidean' distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = hdbscan.HDBSCAN(metric=\"euclidean\",\n",
    "                          min_cluster_size=9,\n",
    "                          algorithm=\"generic\",\n",
    "                          alpha=0.8,\n",
    "                          cluster_selection_method='eom')\n",
    "\n",
    "cluster.fit(data[['x','y','z']].to_numpy())\n",
    "\n",
    "round(ari(data.label,cluster.labels_),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, you may make sure that for the same set of hyperparameters, except metric, algorithm with the 'cosine' distance works better than with 'euclidean' one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the result and print the value of ARI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_galaxies(data,cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "\n",
    "1. **By using any clustering algorithms from *sklearn* with 'cosine' distance try to increase the ARI (0.8857) (+3 score points):**\n",
    "\n",
    "     (+1) if   0.8729 < ARI $\\leq$ 0.88 \n",
    "     \n",
    "     (+2) if   0.88 < ARI $\\leq$ 0.888 \n",
    "     \n",
    "     (+3) if   0.888 < ARI \n",
    "     \n",
    "     \n",
    "2. **By using any clustering algorithms  with any metric of distance try to obtain the ARI greater than 0.9100 (+3 score points):**\n",
    "\n",
    "     (+1) if   0.9  < ARI $\\leq$ 0.905 \n",
    "     \n",
    "     (+2) if   0.905 < ARI $\\leq$ 0.91 \n",
    "     \n",
    "     (+3) if   0.91 < ARI \n",
    "\n",
    "Think, why one distance was better than other?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
