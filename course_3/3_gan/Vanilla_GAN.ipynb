{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vanilla_GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Networks"
      ],
      "metadata": {
        "id": "8On50hZyrOBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, we are going to train a GAN that mimics the images from the MNIST dataset. Most of the code is written for you already, and your task will be to implement some of the techniques that help GANs converge better, as discussed in the lecture material."
      ],
      "metadata": {
        "id": "qb4UyKb0rbgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As always, let's start by importing all the required libraries:"
      ],
      "metadata": {
        "id": "NKL_gx4gsOdI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns3ONetC92pI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import multiprocessing\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning\n",
        "                            # installed by default.\n",
        "                            # Hence, we do it here if necessary\n",
        "    !pip install pytorch-lightning==1.3.4\n",
        "    import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "--FwqdFj_HcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And download the MNIST dataset:"
      ],
      "metadata": {
        "id": "wLpo49xKsVuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "ds_train = MNIST(\".\", train=True, download=True, transform=transform)\n",
        "ds_test = MNIST(\".\", train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "bfuxcTyy_Nly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a helper function to glue together a bunch of images and plot them in a matrix:"
      ],
      "metadata": {
        "id": "AYHfE6dcsaaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def join_images(images):\n",
        "    # We expect `images` to be a 2D array of 2D images represented\n",
        "    # as uint8 numbers (from 0 to 255)\n",
        "    images = np.array(images)\n",
        "    assert images.ndim == 4, \"This function expects the input \" \\\n",
        "                             \"to be a 2D matrix of 2D images\"\n",
        "\n",
        "    # Let's pad our images with the white color to separate the\n",
        "    # nearby images once we glue them together\n",
        "    joined_image = np.pad(\n",
        "        images, ((0, 0), (0, 0), (0, 1), (0, 1)), constant_values=255\n",
        "    )\n",
        "\n",
        "    # Here we transpose and reshape our 4D array to look at it as if\n",
        "    # it was a single 2D image with all the sub-images placed in a\n",
        "    # rectangular grid\n",
        "    joined_image = np.transpose(joined_image, (0, 2, 1, 3))\n",
        "    joined_image = joined_image.reshape(\n",
        "        joined_image.shape[0] * joined_image.shape[1],\n",
        "        joined_image.shape[2] * joined_image.shape[3],\n",
        "    )\n",
        "\n",
        "    # Finally, we pad the top and left sides of our resulting image with\n",
        "    # the white color\n",
        "    joined_image = np.pad(\n",
        "        joined_image, ((1, 0), (1, 0)), constant_values=255\n",
        "    )\n",
        "\n",
        "    return joined_image\n",
        "\n",
        "# A simple function to quickly plot a matrix of images\n",
        "def plot_images(images):\n",
        "    plt.imshow(join_images(images), cmap=\"Greys\")\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "pjD9wAkW_epM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test our functions:"
      ],
      "metadata": {
        "id": "DpnbqnPPt1XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(\n",
        "    ds_train.data.numpy()[:20].reshape(4, 5, 28, 28)\n",
        ")"
      ],
      "metadata": {
        "id": "p5NHxIfzEPes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a brief reminder about GANs.\n",
        "\n",
        "- They consist of two networks: **the generator** ($G$) and **the discriminator** ($D$).\n",
        "- The generator takes in a latent vector $z$ sampled from some known fixed prior distibution $p_z$ (typically, multivariate standard normal) and outputs the generated object.\n",
        "- The discriminator takes in an object (either generated or a real one) and tries to predict whether it is real or not.\n",
        "- The whole thing is trained in steps:\n",
        "    - first, a bunch of discriminator update steps minimizing the negative log-likelihood of its predictions,\n",
        "    - then, a generator update step dragging the discriminator's loss in the opposite direction.\n",
        "\n",
        "Let $D(x)$ be the logit output of our classifier (i.e. the class score without any activation), and let $y\\in\\{0,1\\}$ be the true class of the given object $x$. Then, the negative log-likelihood loss (also known as the binary cross-entropy loss, or just BCE) looks like this:\n",
        "$$l(D(x), y)=-\\left[y\\cdot\\log\\sigma(D(x))+(1-y)\\cdot\\log(1-\\sigma(D(x)))\\right].$$\n",
        "\n",
        "In the case of GAN, the object-target pairs $(x, y)$ will be $(x, 1)$ and $(G(z), 0)$, where $x$ is taken from the training set and $z$ is sampled from the latent distribution. The loss above will be minimized by the discriminator and maximized by the generator.\n",
        "\n",
        "As mentioned in the lectures, the GANs often suffer from problems like vanishing gradients or mode collapse. Here are some techniques that help mitigate these problems:\n",
        "\n",
        "1. **Non-saturating loss.** Early in the training, the generator samples are very different from the training data, and it's very easy for the discriminator to separate them. This may result in the saturation of the generator loss, $\\left[\\log(1-\\sigma(D(G(z))))\\right]$, and therefore no meaningful gradients for the generator. An alternative, *non-saturating* loss for the generator would be $\\left[-\\log\\sigma(D(G(z)))\\right]$. Note that it's equivalent to using the BCE loss above with $l(D(G(z)), y=1)$.\n",
        "2. **Additional noise.** One of the reasons why the mentioned problems may occur is due to the non-overlapping supports of the real and generated distributions. One may artificially make them overlap by smearing the discriminator input with some additional noise. This can be, e.g. multivariate standard normal distribution with some given magnitude.\n",
        "3. **Label swapping.** If the discriminator gets too strong, there's no good gradients for the generator. One of the ways of preventing the discriminator from getting too strong is by randomly swapping the labels for a small fraction of inputs from \"real\" to \"fake\", or vice versa, or both.\n",
        "\n",
        "OK, now we're ready to build our GAN! We'll put everything into a single lightning module. In the code below, **we'll leave blanks for you to implements the techiques 1-3 from above**."
      ],
      "metadata": {
        "id": "ivBgJRsuugzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task (6 points)\n",
        "\n",
        "In the code cell below, fill in the blanks to implement the techniques 1-3 mentioned in the previous text cell:\n",
        "1. **Non-saturating loss** (2 points)\n",
        "2. **Additional noise** (2 points)\n",
        "3. **Label swapping** (2 points)"
      ],
      "metadata": {
        "id": "2FOIErPc_4Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator, # the generator network (torch.Module)\n",
        "        discriminator, # the discriminator network (torch.Module)\n",
        "        latent_size, # the dimensionality of z\n",
        "        num_disc_steps=1, # number of discriminator updates per single generator update\n",
        "        initial_lr=0.001, # initial learning rate\n",
        "        lr_decay_rate=0.95, # a factor, by which the learning rates will be multiplied after each epoch\n",
        "        non_saturating_loss=False, # boolean, whether to use the non-saturating loss\n",
        "        additional_noise_power=None, # float, the magnitude of the additional noise\n",
        "        label_swap_prob=None, # swap each label in the discriminator's loss with this probability\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.latent_size = latent_size\n",
        "        self.num_disc_steps = num_disc_steps\n",
        "        self.initial_lr = initial_lr\n",
        "        self.lr_decay_rate = lr_decay_rate\n",
        "        self.non_saturating_loss = non_saturating_loss\n",
        "        self.additional_noise_power = additional_noise_power\n",
        "        self.label_swap_prob = label_swap_prob\n",
        "\n",
        "        # We'll use this counter to switch between generator and discriminator steps\n",
        "        self._gan_step_counter = 0\n",
        "\n",
        "        # Our loss function\n",
        "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Important: This property activates manual optimization in lightning.\n",
        "        # Since GAN training steps are quite non-standard, we opt for manual\n",
        "        # optimization that we'll implement on our own.\n",
        "        self.automatic_optimization = False\n",
        "\n",
        "    # A function to sample a batch of latent vectors z\n",
        "    def generate_z(self, N):\n",
        "        return torch.randn(N, self.latent_size).to(self.device)\n",
        "\n",
        "    # A function to sample a batch of generated objects G(z)\n",
        "    def generate(self, N):\n",
        "        return self.generator(self.generate_z(N))\n",
        "\n",
        "    # We'll use the function below to calculate both generator's and\n",
        "    # discriminator's losses\n",
        "    def _shared_losses_calculation(self, real_img_batch):\n",
        "        \"\"\"Calculate the loss value on a given batch\"\"\"\n",
        "\n",
        "        batch_size = len(real_img_batch)\n",
        "\n",
        "        # generate a batch of fakes:\n",
        "        fake_img_batch = self.generate(batch_size)\n",
        "\n",
        "        if self.additional_noise_power is not None:\n",
        "            # add random normal noize with the magnitude of\n",
        "            # `self.additional_noise_power` to both fake and real batches\n",
        "\n",
        "            # <YOUR CODE>\n",
        "            raise NotImplementedError # <= remove this\n",
        "\n",
        "\n",
        "        # calculate the discriminator output on real and fake batches:\n",
        "        d_real = self.discriminator(real_img_batch)\n",
        "        d_fake = self.discriminator(fake_img_batch)\n",
        "\n",
        "        # for y=0 and y=1, let's create arrays of labels like this:\n",
        "        labels_1 = torch.ones(\n",
        "            batch_size, 1, dtype=real_img_batch.dtype\n",
        "        ).to(self.device)\n",
        "        labels_0 = torch.zeros(\n",
        "            batch_size, 1, dtype=real_img_batch.dtype\n",
        "        ).to(self.device)\n",
        "\n",
        "        # In the discriminator loss, we'll pass the labels\n",
        "        # after a modification done by the `self.swap_labels`\n",
        "        # function defined below.\n",
        "        d_loss = (\n",
        "            self.criterion(d_real, self.swap_labels(labels_1))\n",
        "            + self.criterion(d_fake, self.swap_labels(labels_0))\n",
        "        )\n",
        "        if not self.non_saturating_loss:\n",
        "            g_loss = -self.criterion(d_fake, labels_0)\n",
        "        else:\n",
        "            # Implement the non-saturating version of the loss for the generator\n",
        "\n",
        "            # g_loss = <YOUR CODE>\n",
        "            raise NotImplementedError # <= remove this\n",
        "\n",
        "\n",
        "        return d_loss, g_loss\n",
        "\n",
        "    # A function to swap labels (0 <=> 1) with a given probability (`self.label_swap_prob`)\n",
        "    def swap_labels(self, labels):\n",
        "        if self.label_swap_prob is None:\n",
        "            return labels\n",
        "\n",
        "        # For each entry in `labels`, randomly swap 0 to 1 and 1 to 0 with\n",
        "        # probability `self.label_swap_prob`, return the result\n",
        "\n",
        "        # <YOUR CODE>\n",
        "        # return <YOUR CODE>\n",
        "        raise NotImplementedError # <= remove this\n",
        "\n",
        "\n",
        "    # This function will be iteratively called by lightning, automatically.\n",
        "    # Here we make our optimization steps.\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # extract the objects, ignore the MNIST labels (digit indicies):\n",
        "        batch, _ = batch\n",
        "\n",
        "        # get the optimizers (see the `configure_optimizers` method below):\n",
        "        d_opt, g_opt = self.optimizers()\n",
        "\n",
        "        # calculate both losses:\n",
        "        d_loss, g_loss = (\n",
        "            self._shared_losses_calculation(batch)\n",
        "        )\n",
        "\n",
        "        # Choose, which update step to make:\n",
        "        if self._gan_step_counter < self.num_disc_steps:\n",
        "            # Making a discriminator step\n",
        "            self._gan_step_counter += 1\n",
        "            d_opt.zero_grad()\n",
        "            self.manual_backward(d_loss) # https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#manual-backward\n",
        "            d_opt.step()\n",
        "        else:\n",
        "            # Making a generator step\n",
        "            self._gan_step_counter = 0\n",
        "            g_opt.zero_grad()\n",
        "            self.manual_backward(g_loss) # https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#manual-backward\n",
        "            g_opt.step()\n",
        "\n",
        "        # Logging our losses\n",
        "        self.log(\"train_loss_discriminator\", d_loss)\n",
        "        self.log(\"train_loss_generator\", g_loss)\n",
        "\n",
        "    # This function will be automatically called by lightning\n",
        "    # at each training epoch end. Inside, we are going to schedule our\n",
        "    # learning rates (see the `configure_optimizers` method below).\n",
        "    def training_epoch_end(self, outputs):\n",
        "        for sch in self.lr_schedulers():\n",
        "            sch.step()\n",
        "\n",
        "    # At the validation step, we'll just calculate the losses and log them.\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        batch, _ = batch\n",
        "        d_loss, g_loss = (\n",
        "            self._shared_losses_calculation(batch)\n",
        "        )\n",
        "        self.log(\"val_loss_discriminator\", d_loss)\n",
        "        self.log(\"val_loss_generator\", g_loss)\n",
        "\n",
        "    # Here, we configure our optimizers for the discriminator and generator,\n",
        "    # along with learning rate schedulers.\n",
        "    def configure_optimizers(self):\n",
        "        d_opt = torch.optim.RMSprop(self.discriminator.parameters(), lr=self.initial_lr)\n",
        "        g_opt = torch.optim.RMSprop(self.generator.parameters(), lr=self.initial_lr)\n",
        "\n",
        "        # A learning rate scheduler is an object that changes the learning rate\n",
        "        # during training. Below, we create ExponentialLR instances to\n",
        "        # exponentially decay the learning rates (multiply the learning rate by\n",
        "        # a factor of 0.95 after each epoch).\n",
        "        d_scheduler = torch.optim.lr_scheduler.ExponentialLR(d_opt, self.lr_decay_rate)\n",
        "        g_scheduler = torch.optim.lr_scheduler.ExponentialLR(g_opt, self.lr_decay_rate)\n",
        "\n",
        "        return [\n",
        "            {\"optimizer\" : d_opt, \"lr_scheduler\" : d_scheduler},\n",
        "            {\"optimizer\" : g_opt, \"lr_scheduler\" : g_scheduler},\n",
        "        ]\n"
      ],
      "metadata": {
        "id": "pP8QXlCEEkh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code cell below defines the generator and discriminator architectures. Since we work with images, we decide to follow the regular deep convolutional network architecture for the discriminator. For the generator, we interleave convolutions and transposed convolutions with residual connections to upsample the images."
      ],
      "metadata": {
        "id": "6twc_YoHHP0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will be our upsampling block with a residual connection:\n",
        "# we'll upsample the input in two ways and then add the results together.\n",
        "# The two upsampling ways are:\n",
        "#   1) with a transposed convolution with a trainable kernel\n",
        "#   2) with a fixed nearest-neighbor interpolation upsampling\n",
        "class UpsampleWithRes(torch.nn.Module):\n",
        "    def __init__(self, upconv, activation, factor, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.path_a = torch.nn.Sequential(\n",
        "            upconv, activation()\n",
        "        )\n",
        "        self.factor = factor\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_a = self.path_a(x)\n",
        "        x_b = torch.nn.functional.interpolate(x, scale_factor=self.factor)\n",
        "        return x_a + x_b\n",
        "\n",
        "# Define the generator architecture\n",
        "class ConvGenerator(torch.nn.Module):\n",
        "    def __init__(self, activation, latent_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(latent_size, 1024),\n",
        "            activation(),\n",
        "        )\n",
        "        self.backbone = torch.nn.Sequential( # 8x8\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=16, out_channels=128, kernel_size=3, padding=1,\n",
        "            ), # -> 8x8\n",
        "            activation(),\n",
        "            UpsampleWithRes(\n",
        "                upconv=torch.nn.ConvTranspose2d(\n",
        "                    in_channels=128, out_channels=128, kernel_size=4, stride=4, padding=0,\n",
        "                ),\n",
        "                activation=activation,\n",
        "                factor=4,\n",
        "            ), # -> 32x32\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=128, out_channels=64, kernel_size=3, padding=0,\n",
        "            ), # -> 30x30\n",
        "            activation(),\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=64, out_channels=32, kernel_size=3, padding=0,\n",
        "            ), # -> 28x28\n",
        "            activation(),\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=32, out_channels=1, kernel_size=1, padding=0,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(\n",
        "            self.fc(x).view(-1, 16, 8, 8)\n",
        "        ).view(-1, 28, 28)\n",
        "\n",
        "\n",
        "# Define the discriminator architecture\n",
        "class ConvDiscriminator(torch.nn.Module):\n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.backbone = torch.nn.Sequential( # 28x28\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=1, out_channels=64, kernel_size=3, padding=1,\n",
        "            ), # -> 28x28\n",
        "            activation(),\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=64, out_channels=128, kernel_size=4, stride=4, padding=0,\n",
        "            ), # -> 7x7\n",
        "            activation(),\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=128, out_channels=128, kernel_size=3, padding=0,\n",
        "            ), # -> 5x5\n",
        "            activation(),\n",
        "            torch.nn.Conv2d(\n",
        "                in_channels=128, out_channels=128, kernel_size=3, padding=0,\n",
        "            ), # -> 3x3\n",
        "            activation(),\n",
        "        )\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(9 * 128, 32),\n",
        "            activation(),\n",
        "            torch.nn.Linear(32, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(\n",
        "            self.backbone(x.view(-1, 1, 28, 28)).view(-1, 9 * 128)\n",
        "        )"
      ],
      "metadata": {
        "id": "ZITbkvPsM9D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we'll create a callback to plot some generator images at the end of each training epoch. We'll store the generated images in tensorboard."
      ],
      "metadata": {
        "id": "d9QVo9-yIyVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlotDigitsCallback(pl.Callback):\n",
        "    def on_train_epoch_end(self, trainer, module):\n",
        "        tensorboard = module.logger.experiment\n",
        "        image = join_images(\n",
        "            (\n",
        "                module.generate(30).detach().cpu().numpy().clip(0, 1).reshape(\n",
        "                    5, 6, 28, 28\n",
        "                ) * 255\n",
        "            ).astype(\"uint8\")\n",
        "        )\n",
        "        tensorboard.add_image(\n",
        "            \"generated_images\",\n",
        "            image,\n",
        "            trainer.global_step, dataformats=\"HW\"\n",
        "        )"
      ],
      "metadata": {
        "id": "BEK1KPDLqzts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's create our networks and the GAN module and a lightning trainer object:"
      ],
      "metadata": {
        "id": "Uneo6CnoJCRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LATENT_SIZE = 128\n",
        "model = GAN(\n",
        "    generator=ConvGenerator(\n",
        "        activation=torch.nn.ELU, latent_size=LATENT_SIZE\n",
        "    ),\n",
        "    discriminator=ConvDiscriminator(\n",
        "        activation=torch.nn.ELU,\n",
        "    ),\n",
        "    latent_size=LATENT_SIZE,\n",
        "    num_disc_steps=1,\n",
        "    initial_lr=0.001,\n",
        "    non_saturating_loss=True,\n",
        "    additional_noise_power=0.05,\n",
        "    label_swap_prob=0.02,\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    ds_train,\n",
        "    batch_size=200,\n",
        "    shuffle=True,\n",
        "    num_workers=multiprocessing.cpu_count(),\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    ds_test, batch_size=2048\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1,\n",
        "    max_epochs=20,\n",
        "    log_every_n_steps=5,\n",
        "    flush_logs_every_n_steps=10,\n",
        "    callbacks=[\n",
        "        PlotDigitsCallback(),\n",
        "        pl.callbacks.LearningRateMonitor(),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "Iva4jETfaN_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize tensorboard to monitor progress."
      ],
      "metadata": {
        "id": "SBglmJrYJTgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start tensorboard.\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "metadata": {
        "id": "mUb8cSiGdcjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we may train our model. While it's training, keep an eye on the tensorboard interface above. You can monitor the losses in the \"SCALARS\" tab, but you should also be able to look at the images produced by the generator in the \"IMAGES\" tab."
      ],
      "metadata": {
        "id": "6icnbx1RJY_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "X1GmFr8Sd1Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot some images that our generator produces:"
      ],
      "metadata": {
        "id": "inONVk6nJxDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(\n",
        "    (model.generate(30).detach().cpu().numpy().clip(0, 1).reshape(5, 6, 28, 28) * 255).astype(\"uint8\")\n",
        ")"
      ],
      "metadata": {
        "id": "CGq7L3aRd6g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "46LDPQNNI8wE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}